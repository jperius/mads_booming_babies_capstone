{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Generate Natality 10 Year - 10 Percent Sample Data</h2>\n",
    "\n",
    "This notebook generates a dataset with a broader time range, with each year contributing 10 percent of its total rows, chosen at random. This dataset is used for recall optimized modeling, controllable factors modeling, and demographic factors modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3543,
     "status": "ok",
     "timestamp": 1763831095984,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "YmGnB0e-N30o",
    "outputId": "2de29b9b-8611-41df-e343-736862594add"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "BASE_DIR = Path().resolve().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wwvr-zMVT5Nf"
   },
   "outputs": [],
   "source": [
    "def normalize_column_names(df):\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "        .str.replace(\"-\", \"_\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_binary_indicators(df, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = (\n",
    "                df[col]\n",
    "                .astype(str).str.strip().str.upper()\n",
    "                .map({\"Y\": 1, \"C\": 1, \"N\": 0})\n",
    "                .astype(\"float\")\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_special_values(df):\n",
    "    df.replace({\n",
    "        9: np.nan,\n",
    "        99: np.nan,\n",
    "        999: np.nan,\n",
    "        9999: np.nan,\n",
    "        99999: np.nan,\n",
    "        99.9: np.nan,\n",
    "        999.9: np.nan,\n",
    "    }, inplace=True)\n",
    "    return df\n",
    "\n",
    "def safe_parse_time_of_day(df):\n",
    "    \"\"\"\n",
    "    Safely parse dob_tt (time of birth) into hour/minute and Fourier encode.\n",
    "    Handles malformed numeric strings and impossible times.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"dob_tt\" not in df.columns:\n",
    "        return df\n",
    "\n",
    "    # Convert to string + strip spaces + zero-pad\n",
    "    ts = df[\"dob_tt\"].astype(str).str.strip().str.zfill(4)\n",
    "\n",
    "    # Only keep values consisting of exactly 4 digits -> otherwise set NaN\n",
    "    ts = ts.where(ts.str.match(r\"^\\d{4}$\"), np.nan)\n",
    "\n",
    "    # Extract H and M safely\n",
    "    hours = pd.to_numeric(ts.str[:2], errors=\"coerce\")\n",
    "    minutes = pd.to_numeric(ts.str[2:], errors=\"coerce\")\n",
    "\n",
    "    # Drop impossible values\n",
    "    invalid_mask = (\n",
    "        (hours < 0) | (hours > 23) |\n",
    "        (minutes < 0) | (minutes > 59)\n",
    "    )\n",
    "\n",
    "    hours[invalid_mask] = np.nan\n",
    "    minutes[invalid_mask] = np.nan\n",
    "\n",
    "    # Compute minute-of-day\n",
    "    minute_of_day = hours * 60 + minutes\n",
    "\n",
    "    # Fourier encodings (NaN-safe)\n",
    "    df[\"time_sin\"] = np.sin(2 * np.pi * minute_of_day / 1440)\n",
    "    df[\"time_cos\"] = np.cos(2 * np.pi * minute_of_day / 1440)\n",
    "\n",
    "    return df\n",
    "\n",
    "def final_feature_engineering(df):\n",
    "\n",
    "    df = df.rename(columns={'no_mmorb': 'morbidity_reported'})\n",
    "\n",
    "    df = df[df['morbidity_reported'] != 9]\n",
    "    # flipping the binary so morbidity is the positive class\n",
    "    df['morbidity_reported'] = 1 - df['morbidity_reported']\n",
    "\n",
    "    df = df.drop(columns=[\"imp_sex\"], errors=\"coerce\")\n",
    "\n",
    "    # Create date from year + week number\n",
    "    if {\"dob_yy\", \"dob_wk\"}.issubset(df.columns):\n",
    "        df[\"date\"] = pd.to_datetime(\n",
    "            df[\"dob_yy\"].astype(str) + df[\"dob_wk\"].astype(str) + \"1\",\n",
    "            format=\"%G%V%u\",\n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    # Safe time-of-day processing\n",
    "    df = safe_parse_time_of_day(df)\n",
    "\n",
    "    #df = df.drop(['dob_tt', 'dob_wk', 'dob_mm'], axis=1)\n",
    "\n",
    "    # Sex binary\n",
    "    if \"sex\" in df.columns:\n",
    "        df[\"sex\"] = np.where(df[\"sex\"] == \"M\", 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-ZmxLPhUrpX"
   },
   "outputs": [],
   "source": [
    "# Feature Filters\n",
    "regex_patterns = ['^mm_', 'no_mmorb', #MaternalMorbidity factors, maternal morbidity\n",
    "                  '^dob_', 'bfacil$','attend$', #date of birth, type of facility of birth, attendant at birth\n",
    "                  '^rf_', '^ip_','^ld_', 'ab_','ca_','me_', #RiskFactors, InfectionPresent, LaborandDelivery, AbnormalConditions, congenital anomalies, method of delivery\n",
    "                  '^ob_',\n",
    "                  'mager$','mrace6','mracehisp', '^mar_p', 'dmar', 'meduc', #mother's demographichs\n",
    "                  '^cig_rec','wtgain$', 'bmi$', 'pwgt_r', 'dwgt_r', #mother's health factors\n",
    "                  'fagecomb','frace6','fracehisp','feduc', #father's demographics\n",
    "                  'dplural', 'sex$','combgest$', 'dbwt', #baby health factors\n",
    "                  '^prior','illb_r$', 'ilop_r$','ilp_r', #prior births living, dead, and terminated timeline\n",
    "                  'previs$', 'precare$', #pregnancy care\n",
    "                  'apgar' #apgar scores, can be either 5 or 10mins\n",
    "                  'wic','pay$',#funding\n",
    "                  ]\n",
    "\n",
    "combined_regex = '|'.join(regex_patterns)\n",
    "\n",
    "# Columns where Y → 1, N → 0\n",
    "binary_patterns = ['^mm_','^rf_', '^ip_','^ld_', '^ab_','^ca_','^me_trial', '^ob_',\n",
    "                   'wic','cig_rec', 'mar_p' ]\n",
    "binary_regex = '|'.join(binary_patterns)\n",
    "exception = {'rf_cesarn', 'rf_fedrg','rf_artec', 'me_trial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l47To1owdI6H"
   },
   "outputs": [],
   "source": [
    "def process_year_file(file, year, chunk_size = 200_000):\n",
    "\n",
    "    yearly_outfile = BASE_DIR / \"data_main\" / \"filtered_aligned_natality_data\" / f\"natality_test_{year}.csv\"\n",
    "    if yearly_outfile.exists():\n",
    "        yearly_outfile.unlink()\n",
    "\n",
    "    print(f\"Processing year {year}: {file}\")\n",
    "\n",
    "    for i, chunk in enumerate(pd.read_csv(file,\n",
    "                                          chunksize=chunk_size,\n",
    "                                          low_memory=False)):\n",
    "\n",
    "        chunk = normalize_column_names(chunk)\n",
    "\n",
    "        # Drop f_ columns\n",
    "        drop_cols = chunk.filter(regex=r\"^f_\").columns\n",
    "        chunk = chunk.drop(columns=drop_cols)\n",
    "\n",
    "        # Subset via regex\n",
    "        filter_cols = chunk.filter(regex=combined_regex).columns\n",
    "        chunk = chunk[filter_cols]\n",
    "\n",
    "        # Clean special codes\n",
    "        chunk = clean_special_values(chunk)\n",
    "\n",
    "        # Convert Y/N → binary\n",
    "        binary_cols = chunk.filter(regex=binary_regex).columns\n",
    "        binary_cols = [c for c in binary_cols if c not in exception]\n",
    "        chunk = convert_binary_indicators(chunk, binary_cols)\n",
    "\n",
    "        chunk = final_feature_engineering(chunk)\n",
    "\n",
    "        chunk.to_csv(\n",
    "            yearly_outfile,\n",
    "            mode=\"a\",\n",
    "            header=not yearly_outfile.exists(),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"  processed {i * chunk_size:,} rows\")\n",
    "\n",
    "    print(f\"Finished year {year}: {yearly_outfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239465,
     "status": "ok",
     "timestamp": 1763840076851,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "z4h9hsqdWU--",
    "outputId": "2c143bbb-c3c8-45be-f940-4afbecb13192"
   },
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = BASE_DIR / \"data_main\" / \"raw_natality_data\"\n",
    "\n",
    "chunk_size = 50_000\n",
    "\n",
    "# Create new cleaned annual files for years after 2013\n",
    "for file in RAW_DATA_DIR.glob(\"natality_data/*.csv\"):\n",
    "    name = os.path.basename(file)\n",
    "    year = int(re.search(r\"(\\d{4})\", name).group(1))\n",
    "    if year > 2013:\n",
    "        process_year_file(file, year, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xg-h8x2WKw99"
   },
   "outputs": [],
   "source": [
    "def process_one_file(file, outfile, chunk_size=200_000, frac=0.10):\n",
    "    print(f\"Sampling from {file}\")\n",
    "\n",
    "    # Iterate chunk by chunk to avoid RAM explosion\n",
    "    for chunk in pd.read_csv(file, chunksize=chunk_size, low_memory=False):\n",
    "\n",
    "        # 10% random sample of this chunk\n",
    "        sampled = chunk.sample(frac=frac, random_state=42)\n",
    "\n",
    "        # Append to output\n",
    "        sampled.to_csv(\n",
    "            outfile,\n",
    "            mode=\"a\",\n",
    "            header=not outfile.exists(),   # header only on first write\n",
    "            index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1225359,
     "status": "ok",
     "timestamp": 1763843163785,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "Q_DcOf0wK-gJ",
    "outputId": "7fa1859c-b7f2-4c40-df12-59333e445a00"
   },
   "outputs": [],
   "source": [
    "IN = BASE_DIR / \"data_main\" / \"filtered_aligned_natality_data\"\n",
    "OUT = BASE_DIR / \"data_main\" / \"natality_aligned_10pct_sample.csv\"\n",
    "\n",
    "# Remove old file if exists\n",
    "if OUT.exists():\n",
    "    OUT.unlink()\n",
    "\n",
    "chunk_size = 50_000\n",
    "\n",
    "# Loop through all CSVs in the folder\n",
    "for file in IN.glob(\"*.csv\"):\n",
    "    process_one_file(file, OUT, chunk_size=chunk_size, frac=0.10)\n",
    "\n",
    "print(f\"\\nFinished! Combined sample saved to:\\n{OUT}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNOhUsXRCRD0xVD2OkF5fyA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "capstone-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
