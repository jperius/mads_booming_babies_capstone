{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10004,
     "status": "ok",
     "timestamp": 1765034900734,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "MOPLzX3Dl4zL"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    learning_curve,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "BASE_DIR = Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14437,
     "status": "ok",
     "timestamp": 1765035042561,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "FzChH4WomCGB",
    "outputId": "989c395b-6023-461a-8ba4-e3303ed488b8"
   },
   "outputs": [],
   "source": [
    "files_path = BASE_DIR / 'data_main' / 'natality_aligned_10pct_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2478,
     "status": "ok",
     "timestamp": 1765035046702,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "L4H4KJLBmPRG",
    "outputId": "8453db10-1297-4709-8d5c-8f4a1f26e829"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dob_yy', 'dob_mm', 'dob_tt', 'dob_wk', 'bfacil', 'mager', 'mrace6',\n",
       "       'mracehisp', 'mar_p', 'dmar', 'meduc', 'fagecomb', 'frace6',\n",
       "       'fracehisp', 'feduc', 'priorlive', 'priordead', 'priorterm', 'illb_r',\n",
       "       'ilop_r', 'ilp_r', 'ilp_r11', 'precare', 'previs', 'cig_rec', 'bmi',\n",
       "       'pwgt_r', 'dwgt_r', 'wtgain', 'rf_pdiab', 'rf_gdiab', 'rf_phype',\n",
       "       'rf_ghype', 'rf_ehype', 'rf_ppterm', 'rf_inftr', 'rf_fedrg', 'rf_artec',\n",
       "       'rf_cesar', 'rf_cesarn', 'ip_gon', 'ip_syph', 'ip_chlam', 'ip_hepb',\n",
       "       'ip_hepc', 'ob_ecvs', 'ob_ecvf', 'ld_indl', 'ld_augm', 'ld_ster',\n",
       "       'ld_antb', 'ld_chor', 'ld_anes', 'me_pres', 'me_rout', 'me_trial',\n",
       "       'mm_mtr', 'mm_plac', 'mm_rupt', 'mm_uhyst', 'mm_aicu',\n",
       "       'morbidity_reported', 'attend', 'pay', 'dplural', 'sex', 'combgest',\n",
       "       'dbwt', 'ab_aven1', 'ab_aven6', 'ab_nicu', 'ab_surf', 'ab_anti',\n",
       "       'ab_seiz', 'ca_anen', 'ca_mnsb', 'ca_cchd', 'ca_cdh', 'ca_omph',\n",
       "       'ca_gast', 'ca_limb', 'ca_cleft', 'ca_clpal', 'ca_down', 'ca_disor',\n",
       "       'ca_hypo', 'date', 'time_sin', 'time_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review Dataframe Columns\n",
    "first_cols = pd.read_csv(files_path, nrows=0).columns\n",
    "first_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1765035047127,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "ZSwP4RBgmRh8"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess(\n",
    "    files_path: Path,\n",
    "    chunk_size: int = 100_000,\n",
    "    sample_frac: float = 1.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads natality data in chunks, applies optional sampling, converts rf_ and ip_\n",
    "    columns to numeric, creates aggregate RF/IP indicators, renames columns, and\n",
    "    returns a numeric DataFrame with Maternal Morbidity as int.\n",
    "    \"\"\"\n",
    "    first_cols = pd.read_csv(files_path, nrows=0).columns\n",
    "\n",
    "    ld_cols = [c for c in first_cols if c.lower().startswith(\"ld_\")]\n",
    "    rf_cols = [c for c in first_cols if c.lower().startswith(\"rf_\")]\n",
    "    ip_cols = [c for c in first_cols if c.lower().startswith(\"ip_\")]\n",
    "\n",
    "    usecols = [\n",
    "        \"bmi\", \"meduc\", \"feduc\", \"precare\", \"previs\", \"cig_rec\",\n",
    "        \"morbidity_reported\", \"bfacil\", \"pay\", \"attend\", \"me_pres\", \"me_rout\",\n",
    "        'date'] + ld_cols + rf_cols + ip_cols\n",
    "\n",
    "    rename_map = {\n",
    "        \"bmi\": \"Body Mass Index\",\n",
    "        \"meduc\": \"Mother Education\",\n",
    "        \"feduc\": \"Father Education\",\n",
    "        \"precare\": \"Pre-natal Care Begins\",\n",
    "        \"previs\": \"Pre-natal Visits\",\n",
    "        \"cig_rec\": \"Cigarette Smoking\",\n",
    "        \"morbidity_reported\": \"Maternal Morbidity\",\n",
    "        \"bfacil\": \"Facility\",\n",
    "        \"pay\": \"Payment Method\",\n",
    "        \"attend\": \"Medical Provider\",\n",
    "        \"ld_indl\": \"Induction of Labor\",\n",
    "        \"ld_augm\": \"Augmentation of Labor\",\n",
    "        \"ld_ster\": \"Steriods Used\",\n",
    "        \"ld_antb\": \"Antibiotics Used\",\n",
    "        \"ld_chor\": \"Chorioamnionitis Present\",\n",
    "        \"ld_anes\": \"Anesthesia Used\",\n",
    "        \"me_pres\": \"Fetal Presentation at Delivery\",\n",
    "        \"me_rout\": \"Final Route of Delivery\",\n",
    "        \"date\": \"Date of Birth\",\n",
    "    }\n",
    "\n",
    "    dfs = []\n",
    "    reader = pd.read_csv(files_path, chunksize=chunk_size, usecols=usecols, low_memory=False)\n",
    "\n",
    "    for chunk in reader:\n",
    "        sampled = chunk.sample(frac=sample_frac, random_state=123)\n",
    "\n",
    "        rf_present = [c for c in rf_cols if c in sampled.columns]\n",
    "        ip_present = [c for c in ip_cols if c in sampled.columns]\n",
    "\n",
    "        if rf_present:\n",
    "            sampled[rf_present] = sampled[rf_present].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "        if ip_present:\n",
    "            sampled[ip_present] = sampled[ip_present].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "        sampled[\"Risk Factor Present\"] = (sampled[rf_present].sum(axis=1) > 0).astype(int)\n",
    "        sampled[\"Infection Present\"] = (sampled[ip_present].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "        sampled.drop(columns=rf_present + ip_present, inplace=True)\n",
    "\n",
    "        sampled.rename(columns=rename_map, inplace=True)\n",
    "        dfs.append(sampled)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    df = df.select_dtypes(include=[np.number]).dropna()\n",
    "    df[\"Maternal Morbidity\"] = df[\"Maternal Morbidity\"].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "executionInfo": {
     "elapsed": 28473,
     "status": "ok",
     "timestamp": 1765035076860,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "r21SASiTmYVe",
    "outputId": "674b4b0d-e22f-404f-9609-379c7cdd2257"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a3653040-9317-471c-896f-32c0485510db",
       "rows": [
        [
         "Facility",
         "0.0"
        ],
        [
         "Mother Education",
         "0.0"
        ],
        [
         "Risk Factor Present",
         "0.0"
        ],
        [
         "Payment Method",
         "0.0"
        ],
        [
         "Medical Provider",
         "0.0"
        ],
        [
         "Maternal Morbidity",
         "0.0"
        ],
        [
         "Final Route of Delivery",
         "0.0"
        ],
        [
         "Fetal Presentation at Delivery",
         "0.0"
        ],
        [
         "Anesthesia Used",
         "0.0"
        ],
        [
         "Chorioamnionitis Present",
         "0.0"
        ],
        [
         "Antibiotics Used",
         "0.0"
        ],
        [
         "Steriods Used",
         "0.0"
        ],
        [
         "Augmentation of Labor",
         "0.0"
        ],
        [
         "Induction of Labor",
         "0.0"
        ],
        [
         "Body Mass Index",
         "0.0"
        ],
        [
         "Cigarette Smoking",
         "0.0"
        ],
        [
         "Pre-natal Visits",
         "0.0"
        ],
        [
         "Pre-natal Care Begins",
         "0.0"
        ],
        [
         "Father Education",
         "0.0"
        ],
        [
         "Infection Present",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 20
       }
      },
      "text/plain": [
       "Facility                          0.0\n",
       "Mother Education                  0.0\n",
       "Risk Factor Present               0.0\n",
       "Payment Method                    0.0\n",
       "Medical Provider                  0.0\n",
       "Maternal Morbidity                0.0\n",
       "Final Route of Delivery           0.0\n",
       "Fetal Presentation at Delivery    0.0\n",
       "Anesthesia Used                   0.0\n",
       "Chorioamnionitis Present          0.0\n",
       "Antibiotics Used                  0.0\n",
       "Steriods Used                     0.0\n",
       "Augmentation of Labor             0.0\n",
       "Induction of Labor                0.0\n",
       "Body Mass Index                   0.0\n",
       "Cigarette Smoking                 0.0\n",
       "Pre-natal Visits                  0.0\n",
       "Pre-natal Care Begins             0.0\n",
       "Father Education                  0.0\n",
       "Infection Present                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_and_preprocess(files_path)\n",
    "summary = df.isna().mean().sort_values(ascending=False)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1765035076864,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "P1rSkrLHnDjd"
   },
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Splits dataset, scales features, applies SMOTE (for final training).\n",
    "    Returns:\n",
    "        X_train_scaled_df, X_test_scaled_df, X_train_res_df,\n",
    "        y_train, y_train_res, y_test, scaler\n",
    "    \"\"\"\n",
    "    X = df.drop(\"Maternal Morbidity\", axis=1)\n",
    "    y = df[\"Maternal Morbidity\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "    X_train_res_df = pd.DataFrame(X_train_res, columns=X.columns)\n",
    "\n",
    "    return (\n",
    "        X_train_scaled_df,\n",
    "        X_test_scaled_df,\n",
    "        X_train_res_df,\n",
    "        y_train,\n",
    "        y_train_res,\n",
    "        y_test,\n",
    "        scaler\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9409,
     "status": "ok",
     "timestamp": 1765035086276,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "QF_jnXEYnJu9",
    "outputId": "dbd9ab1f-0d5d-4d9e-c8c8-6970e18d506f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data (split, scale, SMOTE)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data (split, scale, SMOTE)...\")\n",
    "(\n",
    "    X_train_scaled_df,\n",
    "    X_test_scaled_df,\n",
    "    X_train_res_df,\n",
    "    y_train,\n",
    "    y_train_res,\n",
    "    y_test,\n",
    "    scaler\n",
    ") = prepare_data(df)\n",
    "\n",
    "feature_names = X_train_scaled_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765035086299,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "WoeqfyhDfIAF"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    prob = model.predict_proba(X_test)[:, 1]\n",
    "    preds = (prob > 0.5).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"AUC\": roc_auc_score(y_test, prob),\n",
    "        \"Accuracy\": accuracy_score(y_test, preds),\n",
    "        \"Precision\": precision_score(y_test, preds, zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, preds, zero_division=0),\n",
    "        \"F1\": f1_score(y_test, preds)\n",
    "    }\n",
    "\n",
    "def get_tuning_subset(X, y, frac=0.10, random_state=42):\n",
    "    \"\"\"\n",
    "    Returns a random subset (fraction) of the dataset for faster hyperparameter tuning.\n",
    "    \"\"\"\n",
    "    subset = X.sample(frac=frac, random_state=random_state)\n",
    "    y_subset = y.loc[subset.index]\n",
    "    return subset, y_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1765035817070,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "RjlLOay_fUnx",
    "outputId": "8c482f19-e82e-49ac-830a-015f63605431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating 5% subset for tuning...\n",
      "Tuning subset size: 124,687 rows\n"
     ]
    }
   ],
   "source": [
    "#Select a subset of the total dataset for hyperparameter tuning\n",
    "tuning_frac=0.05\n",
    "print(f\"\\nCreating {int(tuning_frac * 100)}% subset for tuning...\")\n",
    "X_tune, y_tune = get_tuning_subset(X_train_scaled_df, y_train.reset_index(drop=True), frac=tuning_frac)\n",
    "print(f\"Tuning subset size: {X_tune.shape[0]:,} rows\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1765035789309,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "krpnZCOoewa2"
   },
   "outputs": [],
   "source": [
    "def tune_logistic_regression(X, y, cv=None):\n",
    "    if cv is None:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    base = LogisticRegression(\n",
    "        max_iter=300,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"liblinear\"\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        \"C\": np.logspace(-2, 2, 5),\n",
    "        \"penalty\": [\"l1\", \"l2\"],\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        base,\n",
    "        param_grid,\n",
    "        scoring=\"recall\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    print(\"Best Logistic Regression params:\", grid.best_params_)\n",
    "    print(\"Best Logistic Regression 5-fold CV Recall:\", grid.best_score_)\n",
    "\n",
    "    return grid.best_estimator_, grid.best_score_\n",
    "\n",
    "\n",
    "def tune_random_forest(X, y, cv=None):\n",
    "    if cv is None:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    base = RandomForestClassifier(\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    param_dist = {\n",
    "        \"n_estimators\": [100, 200, 400],\n",
    "        \"max_depth\": [5, 10],\n",
    "        \"max_features\": [\"sqrt\", \"log2\"]\n",
    "    }\n",
    "\n",
    "    rand = RandomizedSearchCV(\n",
    "        base,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        scoring=\"recall\",\n",
    "        cv=cv,\n",
    "        n_jobs=1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    rand.fit(X, y)\n",
    "\n",
    "    print(\"Best Random Forest params:\", rand.best_params_)\n",
    "    print(\"Best Random Forest 5-fold CV Recall:\", rand.best_score_)\n",
    "\n",
    "    return rand.best_estimator_, rand.best_score_\n",
    "\n",
    "\n",
    "def tune_xgboost(X, y, cv=None):\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning for XGBoost using a smaller subset and early stopping\n",
    "    on an internal train/validation split.\n",
    "    \"\"\"\n",
    "    if cv is None:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Base XGB model\n",
    "    base_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric=\"aucpr\",\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    param_dist = {\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"n_estimators\": [500],\n",
    "        \"subsample\": [0.7, 0.8],\n",
    "        \"colsample_bytree\": [0.7, 0.9],\n",
    "    }\n",
    "\n",
    "    rand = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,\n",
    "        scoring=\"recall\",\n",
    "        cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    rand.fit(X, y)\n",
    "\n",
    "    print(\"Best params:\", rand.best_params_)\n",
    "    print(\"Best recall:\", rand.best_score_)\n",
    "\n",
    "    return rand.best_estimator_, rand.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "executionInfo": {
     "elapsed": 438450,
     "status": "error",
     "timestamp": 1765036285268,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "FWIWJ-QJfwzt",
    "outputId": "cf837f59-5af2-4508-aba1-d834ba62e789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Logistic Regression...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/opt/homebrew/Cellar/python@3.11/3.11.14_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression params: {'C': np.float64(0.01), 'penalty': 'l1'}\n",
      "Best Logistic Regression 5-fold CV Recall: 0.5361721580127652\n",
      "\n",
      "Tuning Random Forest...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Random Forest params: {'n_estimators': 400, 'max_features': 'log2', 'max_depth': 5}\n",
      "Best Random Forest 5-fold CV Recall: 0.5126582715197516\n",
      "\n",
      "Tuning XGBoost (with early stopping)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best params: {'subsample': 0.8, 'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.1, 'colsample_bytree': 0.7}\n",
      "Best recall: 0.002352941176470588\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning Logistic Regression...\")\n",
    "lr_best, lr_cv_recall = tune_logistic_regression(X_tune, y_tune, cv=cv)\n",
    "\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "rf_best, rf_cv_recall = tune_random_forest(X_tune, y_tune, cv=cv)\n",
    "\n",
    "print(\"\\nTuning XGBoost (with early stopping)...\")\n",
    "xgb_best, xgb_cv_recall = tune_xgboost(X_tune, y_tune, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "executionInfo": {
     "elapsed": 2626857,
     "status": "error",
     "timestamp": 1764969000896,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "4ftrNXcFfwsY",
    "outputId": "b39a86c4-9da3-4212-d8ca-89a88c8e977e"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression & RF refit normally\n",
    "lr_best.fit(X_train_res_df, y_train_res)\n",
    "rf_best.fit(X_train_res_df, y_train_res)\n",
    "\n",
    "# XGBoost refit with early stopping on an internal validation split\n",
    "# X_es_train, X_es_val, y_es_train, y_es_val = make_early_stopping_split(\n",
    "    # X_train_res_df, y_train_res\n",
    "# )\n",
    "\n",
    "xgb_best.fit(\n",
    "    X_train,\n",
    "    y_es_train,\n",
    "    eval_set=[(X_es_val, y_es_val)],\n",
    "    eval_metric=\"aucpr\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Evaluate on hold-out test set\n",
    "print(\"\\nEvaluating tuned models on test set...\")\n",
    "results = []\n",
    "results.append(evaluate_model(lr_best, X_test_scaled_df, y_test, \"Logistic Regression\"))\n",
    "results.append(evaluate_model(rf_best, X_test_scaled_df, y_test, \"Random Forest\"))\n",
    "results.append(evaluate_model(xgb_best, X_test_scaled_df, y_test, \"XGBoost\"))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add CV Recall to the table\n",
    "results_df[\"CV Recall (5-fold)\"] = [\n",
    "    lr_cv_recall,\n",
    "    rf_cv_recall,\n",
    "    xgb_cv_recall\n",
    "]\n",
    "\n",
    "# Pretty printed report\n",
    "print(\"\\n=== Model Performance Comparison ===\")\n",
    "print(results_df.to_string(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VapAzM_fwkr"
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({\"feature\": X_train_res_df.columns})\n",
    "\n",
    "# Logistic Regression (absolute coefficients)\n",
    "feat_imp[\"LR\"] = np.abs(lr_best.coef_[0])\n",
    "feat_imp[\"RF\"] = rf_best.feature_importances_\n",
    "feat_imp[\"XGB\"] = xgb_best.feature_importances_\n",
    "\n",
    "# Normalize each column to make scales comparable\n",
    "for col in [\"LR\", \"RF\", \"XGB\"]:\n",
    "    feat_imp[col] = feat_imp[col] / feat_imp[col].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1281,
     "status": "ok",
     "timestamp": 1764969784923,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "6f7k_LZRfwd_",
    "outputId": "95911498-f81f-4a4c-8493-9765c469a7c5"
   },
   "outputs": [],
   "source": [
    "# Determine global top features across all methods\n",
    "feat_imp[\"mean_importance\"] = feat_imp[[\"LR\", \"RF\", \"XGB\"]].mean(axis=1)\n",
    "top = feat_imp.sort_values(\"mean_importance\", ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "\n",
    "bar_width = 0.25\n",
    "x = np.arange(len(top))\n",
    "\n",
    "plt.barh(x - bar_width, top[\"LR\"], height=bar_width, label=\"Logistic Regression\")\n",
    "plt.barh(x,             top[\"RF\"], height=bar_width, label=\"Random Forest\")\n",
    "plt.barh(x + bar_width, top[\"XGB\"], height=bar_width, label=\"Gradient Boosting\")\n",
    "\n",
    "plt.yticks(x, top[\"feature\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Normalized Feature Importance\")\n",
    "plt.title(\"Feature Importance Comparison (LR vs RF vs XGB)\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2077938,
     "status": "error",
     "timestamp": 1764974159580,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "tXq8t5pQ-XR_",
    "outputId": "b2b93abc-a9bd-4c49-f22e-5154b83ba041"
   },
   "outputs": [],
   "source": [
    "# SHAP analysis\n",
    "explainer = shap.TreeExplainer(xgb_best)\n",
    "shap_values = explainer.shap_values(X_test_scaled_df)\n",
    "\n",
    "# Global importance\n",
    "shap.summary_plot(shap_values, X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "error",
     "timestamp": 1764975916190,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "16674599422508266526"
     },
     "user_tz": 300
    },
    "id": "nbfWdm24y-9v",
    "outputId": "e50b9009-b151-462e-bbac-7637057c437f"
   },
   "outputs": [],
   "source": [
    "pdp_features = [\n",
    "    \"Pre-natal Visits\",\n",
    "    \"Mother Education\",\n",
    "    \"Father Education\",\n",
    "    \"Final Route of Delivery\",\n",
    "    # \"Payment Method\",\n",
    "    \"Body Mass Index\",\n",
    "    \"Medical Provider\",\n",
    "    # \"Risk Factor Present\",\n",
    "]\n",
    "pdp_features = [f for f in pdp_features if f in X_test_scaled_df.columns]\n",
    "\n",
    "if pdp_features:\n",
    "    print(\"\\nPlotting partial dependence plots (XGBoost)...\")\n",
    "    PartialDependenceDisplay\n",
    "    plot_partial_dependence_grid(\n",
    "        xgb_best,\n",
    "        X_test_scaled_df,\n",
    "        pdp_features,\n",
    "        n_rows=3,\n",
    "        n_cols=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhAcXPY9Atbl"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_models(output_dir, lr_model, rf_model, xgb_model, scaler):\n",
    "    \"\"\"\n",
    "    Saves trained models and scaler to disk using joblib.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    joblib.dump(lr_model, output_dir / \"logistic_regression.pkl\")\n",
    "    joblib.dump(rf_model, output_dir / \"random_forest.pkl\")\n",
    "    joblib.dump(xgb_model, output_dir / \"xgboost_model.pkl\")\n",
    "    joblib.dump(scaler, output_dir / \"scaler.pkl\")\n",
    "\n",
    "    print(f\"\\nModels saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcYxZtiHaSVU"
   },
   "outputs": [],
   "source": [
    "save_dir = BASE / \"trained_models\"\n",
    "save_models(save_dir, lr_best, rf_best, xgb_best, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epdbVrExy-6W"
   },
   "outputs": [],
   "source": [
    "def load_models(output_dir):\n",
    "    \"\"\"\n",
    "    Loads previously saved models and scaler.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    lr_model = joblib.load(output_dir / \"logistic_regression.pkl\")\n",
    "    rf_model = joblib.load(output_dir / \"random_forest.pkl\")\n",
    "    xgb_model = joblib.load(output_dir / \"xgboost_model.pkl\")\n",
    "    scaler = joblib.load(output_dir / \"scaler.pkl\")\n",
    "\n",
    "    print(f\"Loaded models from: {output_dir}\")\n",
    "    return lr_model, rf_model, xgb_model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofZzuwH9y-3U"
   },
   "outputs": [],
   "source": [
    "lr_loaded, rf_loaded, xgb_loaded, scaler_loaded = load_models(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "executionInfo": {
     "elapsed": 91928,
     "status": "ok",
     "timestamp": 1764889788260,
     "user": {
      "displayName": "Thomas Lucas",
      "userId": "13156975744940002841"
     },
     "user_tz": 300
    },
    "id": "oBjdluFom7oh",
    "outputId": "e033ddd2-dfb9-4374-bb67-9ffcb4e93e00"
   },
   "outputs": [],
   "source": [
    "## Predictive Modeling using SHAP\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    n_estimators=200,\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    early_stopping_rounds=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_res, y_train_res)\n",
    "pred = model.predict_proba(X_test_scaled)[:,1]\n",
    "print(\"AUC:\", roc_auc_score(y_test, pred))\n",
    "\n",
    "# SHAP analysis\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# Global importance\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCj14BoOo4ac"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "capstone-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
